{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d97467",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5df90e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1d337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from csv\n",
    "df = pd.read_csv('Sarcasm_Model_Dataset.csv')\n",
    "df.head()\n",
    "\n",
    "# Splitting data into test and train (80:20 split)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1064286e",
   "metadata": {},
   "source": [
    "# Frame Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d363c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2636b8c8",
   "metadata": {},
   "source": [
    "# Audio Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd0606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dc3c534",
   "metadata": {},
   "source": [
    "# Text Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fcfd045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           video                                            frame_1  \\\n",
      "104    2_208.mp4  8 8 8 8 8 6 6 6 6 6 7 7 7 6 6 6 5 4 9 23 14 13...   \n",
      "141    2_575.mp4  8 8 6 3 8 12 14 33 44 58 54 24 37 29 35 38 38 ...   \n",
      "4      1_276.mp4  123 124 124 92 31 11 14 15 15 16 15 15 15 13 1...   \n",
      "74   1_10890.mp4  53 58 63 44 59 155 169 168 167 164 163 161 161...   \n",
      "136    2_514.mp4  72 97 132 169 162 136 81 155 191 175 194 195 2...   \n",
      "\n",
      "                                               frame_2  \\\n",
      "104  2 2 2 2 2 2 3 3 3 3 3 2 3 2 1 17 20 14 15 15 1...   \n",
      "141  2 1 5 15 20 19 13 30 49 33 23 32 33 29 24 29 2...   \n",
      "4    93 30 3 4 5 6 5 5 6 6 6 7 7 7 9 5 4 4 6 4 2 5 ...   \n",
      "74   59 57 33 59 70 39 40 46 148 166 161 163 164 16...   \n",
      "136  181 195 222 197 178 210 230 248 230 105 13 15 ...   \n",
      "\n",
      "                                               frame_3         tone  \\\n",
      "104  6 6 6 7 7 7 8 8 7 6 6 7 7 7 7 7 7 9 7 6 7 9 9 ...    2_208.wav   \n",
      "141  14 13 3 1 10 21 19 14 38 42 34 27 45 42 30 26 ...    2_575.wav   \n",
      "4    123 96 29 3 4 5 6 6 6 5 6 6 7 8 8 5 3 5 5 4 2 ...    1_276.wav   \n",
      "74   52 36 34 82 176 165 164 164 164 162 160 158 15...  1_10890.wav   \n",
      "136  40 40 40 40 40 41 41 41 41 40 40 41 40 40 38 3...    2_514.wav   \n",
      "\n",
      "                                                  text  sarcasm sentiment  \\\n",
      "104                   It's that whole sensitive thing.    False   neutral   \n",
      "141  Why? Because she can sing and play guitar and ...     True   neutral   \n",
      "4    Yeah, my parents felt that naming me Leonard a...     True  positive   \n",
      "74   Boy, when you met Bernadette, the field of rob...     True   neutral   \n",
      "136        What's going on?!  That's what's going on!!    False   neutral   \n",
      "\n",
      "      score  sentiment_score  \n",
      "104  0.3712           0.3581  \n",
      "141  0.4350           0.3827  \n",
      "4    0.4099           0.3552  \n",
      "74   0.3734           0.3831  \n",
      "136  0.4166           0.3721  \n",
      "           video                                            frame_1  \\\n",
      "12    1_1001.mp4  125 126 126 126 126 126 126 126 126 127 126 12...   \n",
      "80   1_11699.mp4  66 80 78 77 73 34 25 51 66 61 71 77 60 63 59 4...   \n",
      "33    1_2216.mp4  32 29 23 18 20 21 21 19 19 20 22 23 22 19 14 1...   \n",
      "5      1_410.mp4  179 180 178 177 177 168 111 82 86 95 98 84 76 ...   \n",
      "188     2_53.mp4  11 5 12 23 22 21 21 23 24 29 31 29 27 27 23 20...   \n",
      "\n",
      "                                               frame_2  \\\n",
      "12   125 126 126 126 126 126 126 127 127 126 126 12...   \n",
      "80   32 52 74 78 78 74 64 25 29 42 63 64 68 68 53 6...   \n",
      "33   17 17 17 16 15 16 17 19 19 16 13 11 9 8 7 7 8 ...   \n",
      "5    179 178 177 176 143 86 84 90 99 91 79 76 75 75...   \n",
      "188  29 25 16 16 8 14 70 82 25 9 11 13 16 21 27 28 ...   \n",
      "\n",
      "                                               frame_3         tone  \\\n",
      "12   125 126 126 126 126 125 124 124 124 125 125 12...   1_1001.wav   \n",
      "80   77 74 75 76 85 43 20 27 45 48 55 57 56 61 61 5...  1_11699.wav   \n",
      "33   125 122 122 126 129 129 124 78 44 35 33 34 34 ...   1_2216.wav   \n",
      "5    83 86 93 97 85 78 76 76 76 75 76 76 80 88 100 ...    1_410.wav   \n",
      "188  8 53 92 52 9 17 20 20 24 27 30 32 32 32 32 31 ...     2_53.wav   \n",
      "\n",
      "                                                  text  sarcasm sentiment  \\\n",
      "12      What else? Sell it on eBay as \"slightly used.\"    False  positive   \n",
      "80   No, Stuart picked out those throw pillows all ...     True  positive   \n",
      "33   Excuse me, but what about me? Why don't I get ...    False  positive   \n",
      "5    Leonard, may I present, live from New Delhi, D...    False   neutral   \n",
      "188     You're gonna have to tell me how you did that.    False   neutral   \n",
      "\n",
      "      score  sentiment_score  \n",
      "12   0.4163           0.3660  \n",
      "80   0.3796           0.3578  \n",
      "33   0.3867           0.3413  \n",
      "5    0.4676           0.3981  \n",
      "188  0.3874           0.3785  \n"
     ]
    }
   ],
   "source": [
    "# Load sentiment classifier\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# Classify text and add sentiment and score columns to DataFrame\n",
    "def classify_text(row):\n",
    "    text = row['text']\n",
    "    encoded_input = tokenizer(text, return_tensors='tf')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].numpy()  # Convert TensorFlow tensor to NumPy array\n",
    "    scores = softmax(scores)\n",
    "    ranking = np.argsort(scores)[::-1]\n",
    "    l = config.id2label[ranking[0]]  # Take the label with highest score\n",
    "    s = np.round(float(scores[ranking[0]]), 4)\n",
    "    return pd.Series({'sentiment': l, 'score': s})\n",
    "\n",
    "# Apply classifier to each row in the DataFrame\n",
    "train_df[['sentiment', 'sentiment_score']] = train_df.apply(classify_text, axis=1)\n",
    "test_df[['sentiment', 'sentiment_score']] = test_df.apply(classify_text, axis=1)\n",
    "\n",
    "# Display the DataFrame with new columns\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c44c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['sarcasm_encoded'] = label_encoder.fit_transform(train_df['sarcasm'])\n",
    "test_df['sarcasm_encoded'] = label_encoder.fit_transform(test_df['sarcasm'])\n",
    "\n",
    "# Text preprocessing\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_text_train = tfidf_vectorizer.fit_transform(train_df['text']).toarray()\n",
    "X_text_test = tfidf_vectorizer.transform(test_df['text']).toarray()\n",
    "\n",
    "# Convert sentiment labels to numerical values\n",
    "sentiment_mapping = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "train_df['sentiment_encoded'] = train_df['sentiment'].map(sentiment_mapping)\n",
    "test_df['sentiment_encoded'] = test_df['sentiment'].map(sentiment_mapping)\n",
    "\n",
    "# Combine text features with sentiment scores\n",
    "X_train = np.concatenate((X_text_train, train_df[['sentiment_encoded', 'sentiment_score']].values), axis=1)\n",
    "y_train = train_df['sarcasm_encoded']\n",
    "X_test = np.concatenate((X_text_test, test_df[['sentiment_encoded', 'sentiment_score']].values), axis=1)\n",
    "y_test = test_df['sarcasm_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b4984999",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4606 - loss: 0.6942 - val_accuracy: 0.4706 - val_loss: 0.6942\n",
      "Epoch 2/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6342 - loss: 0.6851 - val_accuracy: 0.5000 - val_loss: 0.6940\n",
      "Epoch 3/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7731 - loss: 0.6767 - val_accuracy: 0.4706 - val_loss: 0.6926\n",
      "Epoch 4/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7974 - loss: 0.6698 - val_accuracy: 0.5000 - val_loss: 0.6912\n",
      "Epoch 5/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8943 - loss: 0.6532 - val_accuracy: 0.5294 - val_loss: 0.6881\n",
      "Epoch 6/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8933 - loss: 0.6320 - val_accuracy: 0.5588 - val_loss: 0.6851\n",
      "Epoch 7/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9377 - loss: 0.6110 - val_accuracy: 0.6176 - val_loss: 0.6813\n",
      "Epoch 8/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9803 - loss: 0.5722 - val_accuracy: 0.6471 - val_loss: 0.6753\n",
      "Epoch 9/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9861 - loss: 0.5194 - val_accuracy: 0.6471 - val_loss: 0.6686\n",
      "Epoch 10/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9561 - loss: 0.4764 - val_accuracy: 0.6765 - val_loss: 0.6624\n",
      "Epoch 11/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9738 - loss: 0.3968 - val_accuracy: 0.6471 - val_loss: 0.6553\n",
      "Epoch 12/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9766 - loss: 0.3353 - val_accuracy: 0.6471 - val_loss: 0.6564\n",
      "Epoch 13/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.2681 - val_accuracy: 0.6765 - val_loss: 0.6528\n",
      "Epoch 14/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.1901 - val_accuracy: 0.6471 - val_loss: 0.6589\n",
      "Epoch 15/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1352 - val_accuracy: 0.6765 - val_loss: 0.6715\n",
      "Epoch 16/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9843 - loss: 0.1084 - val_accuracy: 0.6471 - val_loss: 0.6920\n",
      "Epoch 17/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0781 - val_accuracy: 0.6471 - val_loss: 0.7216\n",
      "Epoch 18/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0581 - val_accuracy: 0.6471 - val_loss: 0.7355\n",
      "Epoch 19/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0457 - val_accuracy: 0.6176 - val_loss: 0.7595\n",
      "Epoch 20/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0324 - val_accuracy: 0.6765 - val_loss: 0.7779\n",
      "Epoch 21/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0246 - val_accuracy: 0.6471 - val_loss: 0.7944\n",
      "Epoch 22/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0220 - val_accuracy: 0.6471 - val_loss: 0.8113\n",
      "Epoch 23/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 0.6765 - val_loss: 0.8265\n",
      "Epoch 24/24\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.6765 - val_loss: 0.8422\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.6951 \n",
      "Test Loss: 0.7864593863487244, Test Accuracy: 0.7857142686843872\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "n_epochs = 24\n",
    "n_batch = 24\n",
    "\n",
    "# Define neural network architecture\n",
    "text_model = Sequential([\n",
    "    Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "text_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "text_model.fit(X_train, y_train, batch_size=n_batch, epochs=n_epochs, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = text_model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c44a304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Predicted Values:\n",
      "[[0.01072609]\n",
      " [0.5455251 ]\n",
      " [0.00740185]\n",
      " [0.52083   ]\n",
      " [0.00933857]\n",
      " [0.11576421]\n",
      " [0.975654  ]\n",
      " [0.9618984 ]\n",
      " [0.9596573 ]\n",
      " [0.615184  ]\n",
      " [0.921876  ]\n",
      " [0.99445546]\n",
      " [0.01215159]\n",
      " [0.61467785]\n",
      " [0.07081493]\n",
      " [0.7728272 ]\n",
      " [0.00598576]\n",
      " [0.42156067]\n",
      " [0.98156613]\n",
      " [0.9834217 ]\n",
      " [0.69449735]\n",
      " [0.93922603]\n",
      " [0.01179704]\n",
      " [0.14391245]\n",
      " [0.4052343 ]\n",
      " [0.05153637]\n",
      " [0.21598184]\n",
      " [0.0503226 ]\n",
      " [0.59129983]\n",
      " [0.03135863]\n",
      " [0.01871938]\n",
      " [0.9851831 ]\n",
      " [0.98319995]\n",
      " [0.86148745]\n",
      " [0.396978  ]\n",
      " [0.06244064]\n",
      " [0.6004945 ]\n",
      " [0.89363825]\n",
      " [0.9924783 ]\n",
      " [0.05810065]\n",
      " [0.05217709]\n",
      " [0.21538955]]\n"
     ]
    }
   ],
   "source": [
    "# Predict values for the test set\n",
    "predictions = text_model.predict(X_test)\n",
    "\n",
    "# Predicted values are the percentage chance that the sample is sarcastic\n",
    "print(\"Predicted Values:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efe38f9",
   "metadata": {},
   "source": [
    "# Sarcasm Detection Model Using Late Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56caee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
